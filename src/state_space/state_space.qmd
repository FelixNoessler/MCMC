---
title: "State space model"
engine: julia
bibliography: ../lit.bib
format:
    html:
        toc: true
        number-sections: true
---


```{dot}
//| fig-width: 7
//| label: fig-hmm
//| fig-cap: "Forward algorithm for a hidden markov model."
digraph HMM {
    node [shape=circle, style=filled, width=0.8];
    
    S1 [label="s(t-1)", fillcolor=white];
    S2 [label="s(t)", fillcolor=white];
    S3 [label="s(t+1)", fillcolor=white];
    Send [label="s(T)", fillcolor=white];

    Xstart [style=invis];
    X0[label="x(0)", fillcolor=lightblue]
    X1 [label="x(t-1)", fillcolor=lightblue];
    X2 [label="x(t)", fillcolor=lightblue];
    X3 [label="x(t+1)", fillcolor=lightblue];
    Xend [label="x(T)", fillcolor=lightblue];

    Y1 [label="y(t-1)", fillcolor=salmon];
    Y2 [label="y(t)", fillcolor=salmon];
    Y3 [label="y(t+1)", fillcolor=salmon];
    Yend [label="y(T)", fillcolor=salmon];

    S1 -> X1 [label = "σₚ,ₜ₋₁"];
    S2 -> X2;
    S3 -> X3;
    Send -> Xend;

    Xstart -> X0 [label="p(x₀)"];
    X0 -> S1 [label="                                       ", style=dashed];  
    X1 -> S2 [label = "p(xₜ | xₜ₋₁)"];
    X2 -> S3;
    X3 -> Send [label="                                       ", style=dashed];

    X1 -> Y1  [label = "σₒ,ₜ₋₁"];
    X2 -> Y2 [label="p(yₜ | xₜ)" ];
    X3 -> Y3; 
    Xend -> Yend;

    { rank=same; S1; S2; S3; Send; }
    { rank=same; Xstart; X0; X1; X2; X3; Xend; }
    { rank=same; Y1; Y2; Y3; Yend; }
}
```



- $s(t)$: state that is modelled with a process-based model at time $t$
- $x(t)$: true hidden state at time $t$
- $y(t)$: observation at time $t$
- $p(x(t) | x(t-1))$: transition probability between the true states
- $p(y(t) | x(t))$: observation probability
- $p(x₀)$: initial state of the true states
- $σₚ$: process error
- $σₒ$: observation error



## Load packages
```{julia}
using AdaptiveParticleMCMC
using AdaptiveMCMC
using CairoMakie
using Distributions
using LabelledArrays
using Statistics
using AdaptiveMCMC
using CairoMakie
using LogDensityProblems
using TransformVariables
using TransformedLogDensities
using UnPack

import MCMCChains
import PairPlots
import StatsPlots
import Random

set_theme!(
    fontsize = 18,
    Axis = (; xgridvisible = false, ygridvisible = false,
            topspinevisible = false, rightspinevisible = false),
    Legend = (; framevisible = false))
```

## Define helper functions

```{julia}
struct ModelContainerMCMC{T1, T2, T3, T4}
    y::T1
    ts::T2
    prior_distributions::T3
    transform::T4
end

function sample_posterior(dat, prob)
    nsamples, nchains, nparameter = size(dat)
    
    vals = dat[sample(1:nsamples), :, sample(1:nchains)]
    ks = collect(keys(prob.prior_distributions))
    
    return (; zip(ks, vals)...)
end
```

# Generate data

```{julia}
Random.seed!(1234)

function generate_data(n_observations; σ_p, σ_o, r, x₀)
    ε_t_dist = Normal(0, σ_p)
    η_t_dist = Normal(0, σ_o)

    ts = 1:n_observations

    s = Array{Float64}(undef, length(ts))
    s_onestep = Array{Float64}(undef, length(ts))
    x = Array{Float64}(undef, length(ts))
    y = Array{Float64}(undef, length(ts))
    K = 20
    
    
    for t in ts
        x_lastt = t == 1 ? x₀ : x[t-1]
        s_lastt = t == 1 ? x₀ : s[t-1]

        ε_t = rand(ε_t_dist)
        s[t] = (1 + r *(1 - s_lastt/K))  * s_lastt
        s_onestep[t] = (1 + r *(1 - x_lastt/K)) * x_lastt  
        x[t] = s_onestep[t] + ε_t

        η_t = rand(η_t_dist)
        y[t] = x[t] + η_t
    end

    (; ts, s, s_onestep, x, y, parameter = (; σ_p, σ_o, r, x₀))
end

Random.seed!(123)
true_solution = generate_data(150; σ_p = 1.5, σ_o = 1.0, r = 0.1, x₀ = 5.0);
```

```{julia}
let
    fig = Figure(size = (1100, 600))
    ax = Axis(fig[1, 1]; xlabel = "time", ylabel = "population size")

    scatter!(true_solution.ts, true_solution.y, color = :red, label = "observations: y")
    lines!(true_solution.ts, true_solution.x, color = :blue, label = "true hidden state: x")
    lines!(true_solution.ts, true_solution.s, color = :grey, label = "process-model state: s")

    Legend(fig[1, 2], ax)
    fig
end
```


# Naive model: ignoring the process error


## Build model
```{julia}
function no_process_error(y, ts)
    prior_dists = (;
        r = Uniform(0, 1),
        K = truncated(Normal(15.0, 10.0); lower = 0),
        σ_o = truncated(Normal(0.0, 1.0); lower = 0),
        x₀ = truncated(Normal(0.0, 10.0); lower = 0))
    transform = as((r = as𝕀, K = asℝ₊, σ_o = asℝ₊, x₀ = asℝ₊))

    ModelContainerMCMC(y, ts, prior_dists, transform)
end

function (prob::ModelContainerMCMC)(θ)
    @unpack r, K, σ_o, x₀ = θ
    @unpack y, ts, prior_distributions = prob

    lprior = 0.0
    for k in keys(prior_distributions)
        lprior += logpdf(prior_distributions[k], θ[k])
    end

    llikelihood = 0.0
    if lprior > -Inf
        x = x₀
        for t in ts
            x = (1 + r *(1 - x/K))* x  
            llikelihood += logpdf(Normal(x, σ_o), y[t])
        end
    end

    return llikelihood + lprior
end

function sample_prior(prob; transform = true)
    @unpack prior_distributions = prob
    
    ks = keys(prior_distributions)
    x = Float64[]
    for k in ks
        push!(x, rand(prior_distributions[k]))
    end
    θ = (; zip(ks, x)...)    

    return transform ? inverse(prob.transform, θ) : θ
end


problem_no_process_error = no_process_error(true_solution.y, true_solution.ts);
ℓ_no_process_error = TransformedLogDensity(problem_no_process_error.transform, problem_no_process_error)
lposterior_no_process_error(x) = LogDensityProblems.logdensity(ℓ_no_process_error, x)

# check that we can sample from prior and calculate the log posterior
lposterior_no_process_error(sample_prior(problem_no_process_error))
```

## Run MCMC
```{julia}
post_no_process_error = let
    nsamples = 100_000; L = 1
    nchains = 4

    post_objs = []
    for i in 1:nchains
        raw_post_chain = adaptive_rwm(sample_prior(problem_no_process_error), 
            lposterior_no_process_error, nsamples; L, b = nsamples ÷ 2, thin = 100);

        post_chain = mapslices(x -> collect(transform(problem_no_process_error.transform, x)),
                            raw_post_chain.X, dims = 1)
        push!(post_objs, post_chain')
    end
    cat(post_objs..., dims = 3)
end;
```

## Analyse results
```{julia}
chn_no_process_error = MCMCChains.Chains(post_no_process_error, 
                                         collect(keys(problem_no_process_error.prior_distributions)))
```

```{julia}
StatsPlots.plot(chn_no_process_error)
```

```{julia}
PairPlots.pairplot(chn_no_process_error) # PairPlots.Truth(true_solution.parameter)
```

## Retrodiction

```{julia}
function retrodict_no_process_error(dat, prob)
    @unpack r, K, x₀ = sample_posterior(dat, prob)
    x = x₀
    x_retro = Array{Float64}(undef, length(true_solution.ts))
    for t in true_solution.ts
        x = (1 + r *(1 - x/K))* x  
        x_retro[t] = x  
    end
    x_retro
end




let
    fig = Figure(size = (1100, 600))
    ax = Axis(fig[1, 1]; xlabel = "time", ylabel = "population size")

    scatter!(true_solution.ts, true_solution.y, color = :red, label = "observations: y")
    lines!(true_solution.ts, true_solution.x, color = :blue, label = "true hidden state: x")
    lines!(true_solution.ts, true_solution.s, color = :grey, label = "process-model state: s")
    
    for i in 1:100
        x_pred = retrodict_no_process_error(post_no_process_error, problem_no_process_error)
        lines!(true_solution.ts, x_pred, color = :green, alpha = 0.1, 
               label = i == 1 ? "fitted (draws from posterior)" : nothing)
    end

    Legend(fig[1, 2], ax)
    fig
end
```

# Modeling the process error without explicit state space representation

## Build model

```{julia}
function ModelScratchMCMC(y, ts)
    prior_dists = (;
        β = Uniform(0, 1),
        σ_p = truncated(Normal(0.0, 1.0); lower = 0),
        σ_o = truncated(Normal(0.0, 1.0); lower = 0),
        x₀ = truncated(Normal(0.0, 10.0); lower = 0))
    transform = as((β = as𝕀, σ_p = asℝ₊, σ_o = asℝ₊, x₀ = asℝ₊))

    ModelScratchMCMC(y, ts, prior_dists, transform)
end

function (problem::ModelScratchMCMC)(θ)
    @unpack β, σ_p, σ_o, x₀ = θ
    @unpack y, ts, prior_distributions = problem

    lprior = 0.0
    lprior += logpdf(prior_distributions[:β], β)
    lprior += logpdf(prior_distributions[:σ_p], σ_o)
    lprior += logpdf(prior_distributions[:σ_p], σ_o)
    lprior += logpdf(prior_distributions[:x₀], x₀)

    llikelihood = 0.0

    if lprior > -Inf
        x = x₀
        for t in ts
            x = β * x + rand(Normal(0, σ_p))
            llikelihood += logpdf(Normal(x, σ_o), y[t])
        end
    end

    return llikelihood + lprior
end
```