---
title: "State space model"
engine: julia
bibliography: ../lit.bib
format:
    html:
        toc: true
        number-sections: true
---


```{dot}
//| fig-width: 7
//| label: fig-hmm
//| fig-cap: "Forward algorithm for a hidden markov model."
digraph HMM {
    node [shape=circle, style=filled, width=0.8];
    
    S1 [label="s(t-1)", fillcolor=white];
    S2 [label="s(t)", fillcolor=white];
    S3 [label="s(t+1)", fillcolor=white];
    Send [label="s(T)", fillcolor=white];

    Xstart [style=invis];
    X0[label="x(0)", fillcolor=lightblue]
    X1 [label="x(t-1)", fillcolor=lightblue];
    X2 [label="x(t)", fillcolor=lightblue];
    X3 [label="x(t+1)", fillcolor=lightblue];
    Xend [label="x(T)", fillcolor=lightblue];

    Y1 [label="y(t-1)", fillcolor=salmon];
    Y2 [label="y(t)", fillcolor=salmon];
    Y3 [label="y(t+1)", fillcolor=salmon];
    Yend [label="y(T)", fillcolor=salmon];

    S1 -> X1 [label = "Ïƒâ‚š,â‚œâ‚‹â‚"];
    S2 -> X2;
    S3 -> X3;
    Send -> Xend;

    Xstart -> X0 [label="p(xâ‚€)"];
    X0 -> S1 [label="                                       ", style=dashed];  
    X1 -> S2 [label = "p(xâ‚œ | xâ‚œâ‚‹â‚)"];
    X2 -> S3;
    X3 -> Send [label="                                       ", style=dashed];

    X1 -> Y1  [label = "Ïƒâ‚’,â‚œâ‚‹â‚"];
    X2 -> Y2 [label="p(yâ‚œ | xâ‚œ)" ];
    X3 -> Y3; 
    Xend -> Yend;

    { rank=same; S1; S2; S3; Send; }
    { rank=same; Xstart; X0; X1; X2; X3; Xend; }
    { rank=same; Y1; Y2; Y3; Yend; }
}
```



- $s(t)$: state that is modelled with a process-based model at time $t$
- $x(t)$: true hidden state at time $t$
- $y(t)$: observation at time $t$
- $p(x(t) | x(t-1))$: transition probability between the true states
- $p(y(t) | x(t))$: observation probability
- $p(xâ‚€)$: initial state of the true states
- $Ïƒâ‚š$: process error
- $Ïƒâ‚’$: observation error



## Load packages
```{julia}
using AdaptiveParticleMCMC
using AdaptiveMCMC
using CairoMakie
using Distributions
using LabelledArrays
using Statistics
using AdaptiveMCMC
using CairoMakie
using LogDensityProblems
using TransformVariables
using TransformedLogDensities
using UnPack

import MCMCChains
import PairPlots
import StatsPlots
import Random

set_theme!(
    fontsize = 18,
    Axis = (; xgridvisible = false, ygridvisible = false,
            topspinevisible = false, rightspinevisible = false),
    Legend = (; framevisible = false))
```

## Define helper functions

```{julia}
struct ModelContainerMCMC{T1, T2, T3, T4}
    y::T1
    ts::T2
    prior_distributions::T3
    transform::T4
end

function sample_posterior(dat, prob)
    nsamples, nchains, nparameter = size(dat)
    
    vals = dat[sample(1:nsamples), :, sample(1:nchains)]
    ks = collect(keys(prob.prior_distributions))
    
    return (; zip(ks, vals)...)
end
```

# Generate data

```{julia}
Random.seed!(1234)

function generate_data(n_observations; Ïƒ_p, Ïƒ_o, r, xâ‚€)
    Îµ_t_dist = Normal(0, Ïƒ_p)
    Î·_t_dist = Normal(0, Ïƒ_o)

    ts = 1:n_observations

    s = Array{Float64}(undef, length(ts))
    s_onestep = Array{Float64}(undef, length(ts))
    x = Array{Float64}(undef, length(ts))
    y = Array{Float64}(undef, length(ts))
    K = 20
    
    
    for t in ts
        x_lastt = t == 1 ? xâ‚€ : x[t-1]
        s_lastt = t == 1 ? xâ‚€ : s[t-1]

        Îµ_t = rand(Îµ_t_dist)
        s[t] = (1 + r *(1 - s_lastt/K))  * s_lastt
        s_onestep[t] = (1 + r *(1 - x_lastt/K)) * x_lastt  
        x[t] = s_onestep[t] + Îµ_t

        Î·_t = rand(Î·_t_dist)
        y[t] = x[t] + Î·_t
    end

    (; ts, s, s_onestep, x, y, parameter = (; Ïƒ_p, Ïƒ_o, r, xâ‚€))
end

Random.seed!(123)
true_solution = generate_data(150; Ïƒ_p = 1.5, Ïƒ_o = 1.0, r = 0.1, xâ‚€ = 5.0);
```

```{julia}
let
    fig = Figure(size = (1100, 600))
    ax = Axis(fig[1, 1]; xlabel = "time", ylabel = "population size")

    scatter!(true_solution.ts, true_solution.y, color = :red, label = "observations: y")
    lines!(true_solution.ts, true_solution.x, color = :blue, label = "true hidden state: x")
    lines!(true_solution.ts, true_solution.s, color = :grey, label = "process-model state: s")

    Legend(fig[1, 2], ax)
    fig
end
```


# Naive model: ignoring the process error


## Build model
```{julia}
function no_process_error(y, ts)
    prior_dists = (;
        r = Uniform(0, 1),
        K = truncated(Normal(15.0, 10.0); lower = 0),
        Ïƒ_o = truncated(Normal(0.0, 1.0); lower = 0),
        xâ‚€ = truncated(Normal(0.0, 10.0); lower = 0))
    transform = as((r = asð•€, K = asâ„â‚Š, Ïƒ_o = asâ„â‚Š, xâ‚€ = asâ„â‚Š))

    ModelContainerMCMC(y, ts, prior_dists, transform)
end

function (prob::ModelContainerMCMC)(Î¸)
    @unpack r, K, Ïƒ_o, xâ‚€ = Î¸
    @unpack y, ts, prior_distributions = prob

    lprior = 0.0
    for k in keys(prior_distributions)
        lprior += logpdf(prior_distributions[k], Î¸[k])
    end

    llikelihood = 0.0
    if lprior > -Inf
        x = xâ‚€
        for t in ts
            x = (1 + r *(1 - x/K))* x  
            llikelihood += logpdf(Normal(x, Ïƒ_o), y[t])
        end
    end

    return llikelihood + lprior
end

function sample_prior(prob; transform = true)
    @unpack prior_distributions = prob
    
    ks = keys(prior_distributions)
    x = Float64[]
    for k in ks
        push!(x, rand(prior_distributions[k]))
    end
    Î¸ = (; zip(ks, x)...)    

    return transform ? inverse(prob.transform, Î¸) : Î¸
end


problem_no_process_error = no_process_error(true_solution.y, true_solution.ts);
â„“_no_process_error = TransformedLogDensity(problem_no_process_error.transform, problem_no_process_error)
lposterior_no_process_error(x) = LogDensityProblems.logdensity(â„“_no_process_error, x)

# check that we can sample from prior and calculate the log posterior
lposterior_no_process_error(sample_prior(problem_no_process_error))
```

## Run MCMC
```{julia}
post_no_process_error = let
    nsamples = 100_000; L = 1
    nchains = 4

    post_objs = []
    for i in 1:nchains
        raw_post_chain = adaptive_rwm(sample_prior(problem_no_process_error), 
            lposterior_no_process_error, nsamples; L, b = nsamples Ã· 2, thin = 100);

        post_chain = mapslices(x -> collect(transform(problem_no_process_error.transform, x)),
                            raw_post_chain.X, dims = 1)
        push!(post_objs, post_chain')
    end
    cat(post_objs..., dims = 3)
end;
```

## Analyse results
```{julia}
chn_no_process_error = MCMCChains.Chains(post_no_process_error, 
                                         collect(keys(problem_no_process_error.prior_distributions)))
```

```{julia}
StatsPlots.plot(chn_no_process_error)
```

```{julia}
PairPlots.pairplot(chn_no_process_error) # PairPlots.Truth(true_solution.parameter)
```

## Retrodiction

```{julia}
function retrodict_no_process_error(dat, prob)
    @unpack r, K, xâ‚€ = sample_posterior(dat, prob)
    x = xâ‚€
    x_retro = Array{Float64}(undef, length(true_solution.ts))
    for t in true_solution.ts
        x = (1 + r *(1 - x/K))* x  
        x_retro[t] = x  
    end
    x_retro
end




let
    fig = Figure(size = (1100, 600))
    ax = Axis(fig[1, 1]; xlabel = "time", ylabel = "population size")

    scatter!(true_solution.ts, true_solution.y, color = :red, label = "observations: y")
    lines!(true_solution.ts, true_solution.x, color = :blue, label = "true hidden state: x")
    lines!(true_solution.ts, true_solution.s, color = :grey, label = "process-model state: s")
    
    for i in 1:100
        x_pred = retrodict_no_process_error(post_no_process_error, problem_no_process_error)
        lines!(true_solution.ts, x_pred, color = :green, alpha = 0.1, 
               label = i == 1 ? "fitted (draws from posterior)" : nothing)
    end

    Legend(fig[1, 2], ax)
    fig
end
```

# Modeling the process error without explicit state space representation

## Build model

```{julia}
function ModelScratchMCMC(y, ts)
    prior_dists = (;
        Î² = Uniform(0, 1),
        Ïƒ_p = truncated(Normal(0.0, 1.0); lower = 0),
        Ïƒ_o = truncated(Normal(0.0, 1.0); lower = 0),
        xâ‚€ = truncated(Normal(0.0, 10.0); lower = 0))
    transform = as((Î² = asð•€, Ïƒ_p = asâ„â‚Š, Ïƒ_o = asâ„â‚Š, xâ‚€ = asâ„â‚Š))

    ModelScratchMCMC(y, ts, prior_dists, transform)
end

function (problem::ModelScratchMCMC)(Î¸)
    @unpack Î², Ïƒ_p, Ïƒ_o, xâ‚€ = Î¸
    @unpack y, ts, prior_distributions = problem

    lprior = 0.0
    lprior += logpdf(prior_distributions[:Î²], Î²)
    lprior += logpdf(prior_distributions[:Ïƒ_p], Ïƒ_o)
    lprior += logpdf(prior_distributions[:Ïƒ_p], Ïƒ_o)
    lprior += logpdf(prior_distributions[:xâ‚€], xâ‚€)

    llikelihood = 0.0

    if lprior > -Inf
        x = xâ‚€
        for t in ts
            x = Î² * x + rand(Normal(0, Ïƒ_p))
            llikelihood += logpdf(Normal(x, Ïƒ_o), y[t])
        end
    end

    return llikelihood + lprior
end
```